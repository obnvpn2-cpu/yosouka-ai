#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ãƒ¬ãƒ¼ã‚¹è©³ç´°æƒ…å ±ã®ãƒãƒƒãƒå–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆpandasç‰ˆã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼å¯¾å¿œ + 100ä»¶ã”ã¨30åˆ†ä¼‘æ†©ï¼‰
"""

import sys
import time
import logging
import argparse
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import sqlite3

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).resolve().parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# ãƒ­ã‚°è¨­å®š
log_dir = project_root / "logs"
log_dir.mkdir(exist_ok=True)
log_file = log_dir / f"batch_race_detail_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_file, encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class RaceDetailBatchProcessor:
    """ãƒ¬ãƒ¼ã‚¹è©³ç´°æƒ…å ±ã®ãƒãƒƒãƒå‡¦ç†ã‚¯ãƒ©ã‚¹ï¼ˆ100ä»¶ã”ã¨30åˆ†ä¼‘æ†©æ©Ÿèƒ½ä»˜ãï¼‰"""
    
    def __init__(self, db_path: str = "data/keiba.db"):
        self.db_path = db_path
        self.conn = None
        self.cursor = None
        
    def connect_db(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š"""
        try:
            self.conn = sqlite3.connect(self.db_path)
            self.cursor = self.conn.cursor()
            logger.info(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šæˆåŠŸ: {self.db_path}")
        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def close_db(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ‡æ–­"""
        if self.conn:
            self.conn.close()
            logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ‡æ–­")
    
    def get_pending_races(
        self, 
        offset: int = 0, 
        limit: Optional[int] = None,
        grade_only: bool = False
    ) -> List[Dict]:
        """è©³ç´°æœªå–å¾—ã®ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‚’å–å¾—"""
        query = """
            SELECT id, race_id, race_name, grade, is_grade_race
            FROM races
            WHERE track_type = 'ä¸æ˜' OR track_type IS NULL
        """
        
        if grade_only:
            query += " AND is_grade_race = 1"
        
        query += " ORDER BY id"
        
        if limit:
            query += f" LIMIT {limit} OFFSET {offset}"
        
        self.cursor.execute(query)
        races = []
        for row in self.cursor.fetchall():
            races.append({
                'id': row[0],
                'race_id': row[1],
                'race_name': row[2],
                'grade': row[3],
                'is_grade_race': row[4]
            })
        
        return races
    
    def get_stats(self) -> Dict:
        """çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        stats = {}
        
        self.cursor.execute("SELECT COUNT(*) FROM races")
        stats['total_races'] = self.cursor.fetchone()[0]
        
        self.cursor.execute("SELECT COUNT(*) FROM races WHERE track_type IS NOT NULL AND track_type != 'ä¸æ˜'")
        stats['completed'] = self.cursor.fetchone()[0]
        
        stats['pending'] = stats['total_races'] - stats['completed']
        
        self.cursor.execute("SELECT COUNT(*) FROM races WHERE is_grade_race = 1")
        stats['grade_races'] = self.cursor.fetchone()[0]
        
        self.cursor.execute("""
            SELECT COUNT(*) FROM races 
            WHERE is_grade_race = 1 AND (track_type IS NULL OR track_type = 'ä¸æ˜')
        """)
        stats['grade_pending'] = self.cursor.fetchone()[0]
        
        return stats
    
    def _sleep_with_countdown(self, seconds: int, message: str):
        """ã‚«ã‚¦ãƒ³ãƒˆãƒ€ã‚¦ãƒ³ä»˜ãä¼‘æ†©"""
        logger.info(f"ğŸ’¤ {message}")
        logger.info(f"   ä¼‘æ†©æ™‚é–“: {seconds}ç§’ï¼ˆ{seconds/60:.0f}åˆ†ï¼‰")
        
        remaining = seconds
        start_time = time.time()
        
        while remaining > 0:
            mins = remaining // 60
            secs = remaining % 60
            
            if remaining == seconds or remaining % 60 == 0:  # é–‹å§‹æ™‚ã¨1åˆ†ã”ã¨
                eta = datetime.now() + timedelta(seconds=remaining)
                logger.info(f"   â° æ®‹ã‚Š: {mins}åˆ†{secs}ç§’ | å†é–‹äºˆå®š: {eta.strftime('%H:%M:%S')}")
            
            time.sleep(min(60, remaining))  # æœ€å¤§1åˆ†å¾…æ©Ÿ
            elapsed = int(time.time() - start_time)
            remaining = seconds - elapsed
        
        logger.info(f"   âœ… ä¼‘æ†©çµ‚äº†ã€‚å‡¦ç†ã‚’å†é–‹ã—ã¾ã™ã€‚")
    
    def process_batch(
        self,
        offset: int = 0,
        limit: Optional[int] = None,
        grade_only: bool = False,
        sleep_interval: int = 3,
        batch_interval: int = 1800  # 100ä»¶ã”ã¨ã®ä¼‘æ†©æ™‚é–“ï¼ˆç§’ï¼‰ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ30åˆ†
    ):
        """ãƒãƒƒãƒå‡¦ç†ã‚’å®Ÿè¡Œ"""
        self.connect_db()
        
        try:
            # çµ±è¨ˆè¡¨ç¤º
            stats = self.get_stats()
            logger.info("=" * 60)
            logger.info("ãƒ¬ãƒ¼ã‚¹è©³ç´°ãƒãƒƒãƒå‡¦ç†é–‹å§‹ï¼ˆpandasç‰ˆ + 100ä»¶ã”ã¨ä¼‘æ†©ï¼‰")
            logger.info("=" * 60)
            logger.info(f"ç·ãƒ¬ãƒ¼ã‚¹æ•°: {stats['total_races']}ä»¶")
            logger.info(f"è©³ç´°å–å¾—æ¸ˆã¿: {stats['completed']}ä»¶ ({stats['completed']/stats['total_races']*100:.1f}%)")
            logger.info(f"è©³ç´°æœªå–å¾—: {stats['pending']}ä»¶")
            logger.info(f"é‡è³: {stats['grade_races']}ä»¶ï¼ˆæœªå–å¾—: {stats['grade_pending']}ä»¶ï¼‰")
            logger.info("=" * 60)
            
            # å‡¦ç†å¯¾è±¡ãƒ¬ãƒ¼ã‚¹å–å¾—
            races = self.get_pending_races(offset, limit, grade_only)
            
            if not races:
                logger.info("å‡¦ç†å¯¾è±¡ã®ãƒ¬ãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“")
                return
            
            logger.info(f"å‡¦ç†å¯¾è±¡: {len(races)}ä»¶")
            if grade_only:
                logger.info("ï¼ˆé‡è³ã®ã¿ï¼‰")
            logger.info(f"ç¯„å›²: offset={offset}, limit={limit}")
            
            # æ¨å®šæ™‚åˆ»ã‚’è¨ˆç®—
            num_batches = (len(races) - 1) // 100  # ä¼‘æ†©å›æ•°
            estimated_process_time = len(races) * 6  # ç§’ï¼ˆå¹³å‡6ç§’/ä»¶ï¼‰
            estimated_wait_time = len(races) * sleep_interval  # ãƒ¬ãƒ¼ã‚¹é–“å¾…æ©Ÿ
            estimated_interval_time = num_batches * batch_interval  # 100ä»¶ã”ã¨ä¼‘æ†©
            total_estimated_time = estimated_process_time + estimated_wait_time + estimated_interval_time
            estimated_completion = datetime.now() + timedelta(seconds=total_estimated_time)
            
            logger.info(f"")
            logger.info(f"â±ï¸  æ¨å®šæ‰€è¦æ™‚é–“: {total_estimated_time/3600:.1f}æ™‚é–“")
            logger.info(f"   - å‡¦ç†æ™‚é–“: {estimated_process_time/60:.0f}åˆ†")
            logger.info(f"   - ãƒ¬ãƒ¼ã‚¹é–“å¾…æ©Ÿ: {estimated_wait_time/60:.0f}åˆ†")
            logger.info(f"   - 100ä»¶ã”ã¨ä¼‘æ†©: {num_batches}å› Ã— {batch_interval/60:.0f}åˆ† = {estimated_interval_time/60:.0f}åˆ†")
            logger.info(f"ğŸ¯ æ¨å®šå®Œäº†æ™‚åˆ»: {estimated_completion.strftime('%Y-%m-%d %H:%M:%S')}")
            logger.info("=" * 60)
            
            # race_detail_scraperã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            try:
                from backend.scraper.race_detail_scraper_with_db import scrape_race_detail
            except ImportError:
                logger.error("race_detail_scraper_with_db.pyãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                logger.error("backend/scraper/race_detail_scraper_with_db.pyãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
                return
            
            # å‡¦ç†é–‹å§‹
            success_count = 0
            error_count = 0
            start_time = time.time()
            
            for i, race in enumerate(races, 1):
                try:
                    logger.info(f"\n[{i}/{len(races)}] å‡¦ç†ä¸­: {race['race_name']} (race_id: {race['race_id']})")
                    if race['is_grade_race']:
                        logger.info(f"  ã‚°ãƒ¬ãƒ¼ãƒ‰: {race['grade']}")
                    
                    # ãƒ¬ãƒ¼ã‚¹è©³ç´°å–å¾—
                    success = scrape_race_detail(race['race_id'], self.db_path)
                    
                    if success:
                        success_count += 1
                        logger.info(f"  âœ… æˆåŠŸ ({success_count}/{len(races)})")
                    else:
                        error_count += 1
                        logger.warning(f"  âŒ å¤±æ•— ({error_count}/{len(races)})")
                    
                    # é€²æ—è¡¨ç¤º
                    elapsed = time.time() - start_time
                    avg_time = elapsed / i
                    remaining_races = len(races) - i
                    remaining_batches = remaining_races // 100
                    remaining_process_time = remaining_races * avg_time
                    remaining_interval_time = remaining_batches * batch_interval
                    total_remaining = remaining_process_time + remaining_interval_time
                    
                    eta = datetime.now() + timedelta(seconds=total_remaining)
                    logger.info(f"  é€²æ—: {i/len(races)*100:.1f}% | çµŒé: {elapsed/60:.1f}åˆ† | æ®‹ã‚Š: {total_remaining/60:.1f}åˆ† | ETA: {eta.strftime('%H:%M:%S')}")
                    
                    # 100ä»¶ã”ã¨ã«30åˆ†ä¼‘æ†©ï¼ˆæœ€å¾Œã®ãƒ¬ãƒ¼ã‚¹ã§ãªã„å ´åˆï¼‰
                    if i % 100 == 0 and i < len(races):
                        logger.info("")
                        logger.info("ğŸ‰" + "=" * 58)
                        logger.info(f"ğŸ‰ 100ä»¶å‡¦ç†å®Œäº†ï¼ ({i}/{len(races)}ä»¶)")
                        logger.info("ğŸ‰" + "=" * 58)
                        self._sleep_with_countdown(
                            batch_interval,
                            f"netkeiba.comã¸ã®è² è·è»½æ¸›ã®ãŸã‚{batch_interval/60:.0f}åˆ†ä¼‘æ†©ã—ã¾ã™..."
                        )
                        logger.info("")
                        logger.info("ğŸš€" + "=" * 58)
                        logger.info(f"ğŸš€ å‡¦ç†å†é–‹: æ®‹ã‚Š{len(races)-i}ä»¶")
                        logger.info("ğŸš€" + "=" * 58)
                    
                    # ãƒ¬ãƒ¼ã‚¹é–“å¾…æ©Ÿï¼ˆæœ€å¾Œã®ãƒ¬ãƒ¼ã‚¹ä»¥å¤–ã€ã‹ã¤100ä»¶ç›®ã§ãªã„å ´åˆï¼‰
                    elif i < len(races):
                        logger.info(f"  å¾…æ©Ÿ: {sleep_interval}ç§’...")
                        time.sleep(sleep_interval)
                    
                except Exception as e:
                    error_count += 1
                    logger.error(f"  ã‚¨ãƒ©ãƒ¼: {race['race_name']} - {e}")
                    continue
            
            # çµæœã‚µãƒãƒªãƒ¼
            total_time = time.time() - start_time
            logger.info("\n" + "=" * 60)
            logger.info("ğŸŠ ãƒãƒƒãƒå‡¦ç†å®Œäº†")
            logger.info("=" * 60)
            logger.info(f"å‡¦ç†ä»¶æ•°: {len(races)}ä»¶")
            logger.info(f"æˆåŠŸ: {success_count}ä»¶ ({success_count/len(races)*100:.1f}%)")
            logger.info(f"å¤±æ•—: {error_count}ä»¶ ({error_count/len(races)*100:.1f}%)")
            logger.info(f"å‡¦ç†æ™‚é–“: {total_time/3600:.1f}æ™‚é–“ ({total_time/60:.1f}åˆ†)")
            logger.info(f"å¹³å‡å‡¦ç†æ™‚é–“: {total_time/len(races):.1f}ç§’/ä»¶")
            logger.info("=" * 60)
            
            # æœ€æ–°çµ±è¨ˆ
            stats = self.get_stats()
            logger.info(f"\nç¾åœ¨ã®çŠ¶æ³:")
            logger.info(f"è©³ç´°å–å¾—æ¸ˆã¿: {stats['completed']}/{stats['total_races']}ä»¶ ({stats['completed']/stats['total_races']*100:.1f}%)")
            logger.info(f"è©³ç´°æœªå–å¾—: {stats['pending']}ä»¶")
            
        finally:
            self.close_db()


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(description='ãƒ¬ãƒ¼ã‚¹è©³ç´°æƒ…å ±ã®ãƒãƒƒãƒå–å¾—ï¼ˆpandasç‰ˆ + 100ä»¶ã”ã¨ä¼‘æ†©ï¼‰')
    
    parser.add_argument('--offset', type=int, default=0, help='é–‹å§‹ä½ç½®ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0ï¼‰')
    parser.add_argument('--limit', type=int, default=None, help='å–å¾—ä»¶æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: å…¨ä»¶ï¼‰')
    parser.add_argument('--grade-only', action='store_true', help='é‡è³ã®ã¿å–å¾—')
    parser.add_argument('--sleep', type=int, default=3, help='å„ãƒ¬ãƒ¼ã‚¹å‡¦ç†å¾Œã®å¾…æ©Ÿç§’æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3ï¼‰')
    parser.add_argument('--batch-interval', type=int, default=1800, help='100ä»¶ã”ã¨ã®ä¼‘æ†©æ™‚é–“ï¼ˆç§’ï¼‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1800ç§’=30åˆ†ï¼‰')
    parser.add_argument('--db', type=str, default='data/keiba.db', help='ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹')
    
    args = parser.parse_args()
    
    logger.info("")
    logger.info("=" * 60)
    logger.info("âš™ï¸  è¨­å®š:")
    logger.info(f"   ãƒ¬ãƒ¼ã‚¹é–“å¾…æ©Ÿ: {args.sleep}ç§’")
    logger.info(f"   100ä»¶ã”ã¨ä¼‘æ†©: {args.batch_interval}ç§’ ({args.batch_interval/60:.0f}åˆ†)")
    logger.info("=" * 60)
    logger.info("")
    
    # ãƒãƒƒãƒå‡¦ç†å®Ÿè¡Œ
    processor = RaceDetailBatchProcessor(args.db)
    processor.process_batch(
        offset=args.offset,
        limit=args.limit,
        grade_only=args.grade_only,
        sleep_interval=args.sleep,
        batch_interval=args.batch_interval
    )


if __name__ == "__main__":
    main()
